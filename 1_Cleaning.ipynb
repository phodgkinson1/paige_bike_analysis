{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "d0dQ6iUGOIy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ACS 5-Year 2025 Means of Transport Loading/Cleaning\n",
        "\n"
      ],
      "metadata": {
        "id": "GlER1Lc3tJNz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLKMosRVN_II"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "acs = pd.read_csv('/content/ACS_5Year_2023_Means_of_Transport.csv')\n",
        "\n",
        "# Get a list of all column names\n",
        "all_columns = acs.columns.tolist()\n",
        "\n",
        "# Filter columns to keep only \"Estimate\" columns\n",
        "estimate_columns = [col for col in all_columns if 'Estimate' in col and 'Margin of Error' not in col]\n",
        "\n",
        "# Keep the \"Label (Grouping)\" column and the selected \"Estimate\" columns\n",
        "acs = acs[['Label (Grouping)'] + estimate_columns]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keep only bike data and total commuter data\n",
        "acs = acs.iloc[[0, 17]]\n",
        "#print(acs.head(1))\n"
      ],
      "metadata": {
        "id": "5MhT8E68Pla6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all values to numeric from strings, ignoring the first column\n",
        "for i in range(acs.shape[0]):\n",
        "    for j in range(1, acs.shape[1]):  # Start from column 1\n",
        "        try:\n",
        "            # Replace commas in string numbers before conversion\n",
        "            value = acs.iloc[i, j]\n",
        "            if isinstance(value, str):\n",
        "                value = value.replace(',', '')\n",
        "            acs.iloc[i, j] = pd.to_numeric(value, errors='coerce')\n",
        "        except ValueError:\n",
        "            # Handle non-numeric strings (e.g., keep them as strings or assign NaN)\n",
        "            pass  # Or acs.iloc[i, j] = np.nan\n"
      ],
      "metadata": {
        "id": "6h3UAM0gdhi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the new row data with the string label\n",
        "new_row = ['% Bike Commuter']\n",
        "\n",
        "# Extend the new row with zeros to match the number of numeric columns\n",
        "new_row.extend([0] * (len(acs.columns) - 1))\n",
        "\n",
        "# Create a new DataFrame with the new row\n",
        "new_row_df = pd.DataFrame([new_row], columns=acs.columns)\n",
        "\n",
        "# Append the new row DataFrame to the original DataFrame\n",
        "acs = pd.concat([acs, new_row_df], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "O8oTMSG1eGwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the data type of all columns except the first one to float64\n",
        "for col in acs.columns[1:]:\n",
        "    acs[col] = acs[col].astype(float)  # Convert to float64\n",
        "\n",
        "for i in range(1, len(acs.columns)):\n",
        "    try:\n",
        "        # Get numerator and denominator\n",
        "        numerator = pd.to_numeric(acs.iloc[1, i])\n",
        "        denominator = pd.to_numeric(acs.iloc[0, i])\n",
        "\n",
        "        # Check for zero denominator or NaN values\n",
        "        if denominator == 0 or np.isnan(numerator) or np.isnan(denominator):\n",
        "            acs.iloc[2, i] = 0 if denominator == 0 else np.nan  # Assign 0 if total is 0, NaN otherwise\n",
        "        else:\n",
        "            # Cast the result to float64 before assigning\n",
        "            acs.iloc[2, i] = ((numerator / denominator) * 100).astype(float)  # This line should no longer cause a warning\n",
        "\n",
        "    except (ValueError, TypeError):\n",
        "        acs.iloc[2, i] = np.nan  # Assign NaN for other errors"
      ],
      "metadata": {
        "id": "x-qHoRJUec2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_tract_and_convert_to_geoid(value):\n",
        "    \"\"\"\n",
        "    Extracts the tract number from a string and converts it to a full GEOID,\n",
        "    replacing the entire cell value.\n",
        "\n",
        "    Args:\n",
        "        value: A string in the format \"Census Tract 101.01; San Francisco County; California!!Estimate\"\n",
        "               or \"Census Tract 106; San Francisco County; California!!Estimate\"\n",
        "\n",
        "    Returns:\n",
        "        The full GEOID (e.g., 6075010101) or the original value if no tract is found.\n",
        "    \"\"\"\n",
        "    # Ensure value is a string before applying regex\n",
        "    if isinstance(value, bytes):\n",
        "        value = value.decode('utf-8', errors='ignore')\n",
        "    elif not isinstance(value, str):  # Handle non-string, non-bytes values\n",
        "        return value\n",
        "\n",
        "    # Updated regex to handle tracts with or without decimals\n",
        "    match = re.search(r\"Census Tract (\\d+(?:\\.\\d+)?)\", value)\n",
        "    if match:\n",
        "        tract_number = match.group(1).replace(\".\", \"\")  # Remove the decimal if present\n",
        "        full_geoid = \"06075\" + tract_number.zfill(6)  # Add state and county FIPS, pad with zeros\n",
        "        return full_geoid  # Return only the GEOID if found\n",
        "    return value  # Return original value if no match\n",
        "\n",
        "# Apply the function directly to the column names (header)\n",
        "acs.columns = acs.columns.map(extract_tract_and_convert_to_geoid)\n",
        "\n",
        "# Print the DataFrame to verify changes\n",
        "print(acs.head(0))  # Print only the header row"
      ],
      "metadata": {
        "id": "21A9k7KgZybz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0df2f2d-97ea-464e-ff12-7a311911f420",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Label (Grouping), 06075010101, 06075010102, 06075010201, 06075010202, 06075000103, 06075010401, 06075010402, 06075000105, 06075000106, 06075010701, 06075010702, 06075000108, 06075010901, 06075010902, 06075011001, 06075011002, 06075011101, 06075011102, 06075000112, 06075000113, 06075000117, 06075000118, 06075011901, 06075011902, 06075012001, 06075012002, 06075000121, 06075012202, 06075012203, 06075012204, 06075012301, 06075012302, 06075012403, 06075012404, 06075012405, 06075012406, 06075012502, 06075012503, 06075012504, 06075012601, 06075012602, 06075000127, 06075012801, 06075012802, 06075012901, 06075012902, 06075013001, 06075013002, 06075013101, 06075013102, 06075000132, 06075000133, 06075013401, 06075013402, 06075000135, 06075000151, 06075015201, 06075015202, 06075000153, 06075015401, 06075015402, 06075000155, 06075000156, 06075015701, 06075015702, 06075015801, 06075015802, 06075000159, 06075000160, 06075016101, 06075016102, 06075000162, 06075000163, 06075000164, 06075000165, 06075016601, 06075016602, 06075000167, 06075016801, 06075016802, 06075000169, 06075000170, 06075017101, 06075017102, 06075017602, 06075017603, 06075017604, 06075000177, 06075017801, 06075017803, 06075017804, 06075017903, 06075000180, 06075020101, 06075020102, 06075020201, 06075020202, 06075000203, 06075020401, ...]\n",
            "Index: []\n",
            "\n",
            "[0 rows x 245 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acs.to_csv('ACS_cleaned.csv', index=False)\n",
        "files.download('ACS_cleaned.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE1fgWlqttig",
        "outputId": "f30c0c49-278f-43bf-d606-f21b5364698d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_284db96c-02fb-4ca2-8c74-3957a3398f44\", \"ACS_cleaned.csv\", 9802)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crashes Loading/Cleaning"
      ],
      "metadata": {
        "id": "49z9fMdttGsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "crashes = pd.read_csv('/content/Crashes.csv')\n",
        "# Get a list of all column names\n",
        "all_columns = crashes.columns.tolist()\n",
        "print(all_columns)\n",
        "#print(crashes.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqSIcsDE_HqR",
        "outputId": "9c84a38b-9cf9-46d3-875e-d09ad12d2a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CASE_ID', 'ACCIDENT_YEAR', 'PROC_DATE', 'JURIS', 'COLLISION_DATE', 'COLLISION_TIME', 'OFFICER_ID', 'REPORTING_DISTRICT', 'DAY_OF_WEEK', 'CHP_SHIFT', 'POPULATION', 'CNTY_CITY_LOC', 'SPECIAL_COND', 'BEAT_TYPE', 'CHP_BEAT_TYPE', 'CITY_DIVISION_LAPD', 'CHP_BEAT_CLASS', 'BEAT_NUMBER', 'PRIMARY_RD', 'SECONDARY_RD', 'DISTANCE', 'DIRECTION', 'INTERSECTION', 'WEATHER_1', 'WEATHER_2', 'STATE_HWY_IND', 'CALTRANS_COUNTY', 'CALTRANS_DISTRICT', 'STATE_ROUTE', 'ROUTE_SUFFIX', 'POSTMILE_PREFIX', 'POSTMILE', 'LOCATION_TYPE', 'RAMP_INTERSECTION', 'SIDE_OF_HWY', 'TOW_AWAY', 'COLLISION_SEVERITY', 'NUMBER_KILLED', 'NUMBER_INJURED', 'PARTY_COUNT', 'PRIMARY_COLL_FACTOR', 'PCF_CODE_OF_VIOL', 'PCF_VIOL_CATEGORY', 'PCF_VIOLATION', 'PCF_VIOL_SUBSECTION', 'HIT_AND_RUN', 'TYPE_OF_COLLISION', 'MVIW', 'PED_ACTION', 'ROAD_SURFACE', 'ROAD_COND_1', 'ROAD_COND_2', 'LIGHTING', 'CONTROL_DEVICE', 'CHP_ROAD_TYPE', 'PEDESTRIAN_ACCIDENT', 'BICYCLE_ACCIDENT', 'MOTORCYCLE_ACCIDENT', 'TRUCK_ACCIDENT', 'NOT_PRIVATE_PROPERTY', 'ALCOHOL_INVOLVED', 'STWD_VEHTYPE_AT_FAULT', 'CHP_VEHTYPE_AT_FAULT', 'COUNT_SEVERE_INJ', 'COUNT_VISIBLE_INJ', 'COUNT_COMPLAINT_PAIN', 'COUNT_PED_KILLED', 'COUNT_PED_INJURED', 'COUNT_BICYCLIST_KILLED', 'COUNT_BICYCLIST_INJURED', 'COUNT_MC_KILLED', 'COUNT_MC_INJURED', 'PRIMARY_RAMP', 'SECONDARY_RAMP', 'LATITUDE', 'LONGITUDE', 'COUNTY', 'CITY', 'POINT_X', 'POINT_Y']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(crashes[['WEATHER_1', 'WEATHER_2']].head(10))  # Prints the first 10 rows\n"
      ],
      "metadata": {
        "id": "LEmJNfaxi4-5",
        "outputId": "4da114cc-6bdf-4110-bc7e-75abcec09ab3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  WEATHER_1 WEATHER_2\n",
            "0         A         -\n",
            "1         A         -\n",
            "2         A         -\n",
            "3         A         -\n",
            "4         B         -\n",
            "5         A         -\n",
            "6         A         -\n",
            "7         A         -\n",
            "8         A         -\n",
            "9         A         -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#keep 'ALCOHOL_INVOLVED' 'COLLISION_TIME' 'DAY_OF_WEEK' 'LOCATION_TYPE'  'COLLISION_SEVERITY', 'NUMBER_KILLED', 'NUMBER_INJURED', 'PARTY_COUNT', 'LATITUDE', 'LONGITUDE''POINT_X', 'POINT_Y'\n",
        "columns_to_keep = ['ALCOHOL_INVOLVED', 'COLLISION_TIME', 'PRIMARY_RD', 'SECONDARY_RD', 'DAY_OF_WEEK', 'LOCATION_TYPE', 'COLLISION_SEVERITY', 'NUMBER_KILLED', 'NUMBER_INJURED', 'PARTY_COUNT', 'LATITUDE', 'LONGITUDE', 'POINT_X', 'POINT_Y']\n",
        "crashes = crashes[columns_to_keep]\n",
        "\n",
        "all_columns = crashes.columns.tolist()\n",
        "#print(all_columns)\n",
        "#remove rows where 'ALCOHOL_INVOLVED' and delete col\n",
        "filtered_crashes = crashes[crashes['ALCOHOL_INVOLVED'].isna()]\n",
        "filtered_crashes = filtered_crashes.drop('ALCOHOL_INVOLVED', axis=1)\n",
        "#print(crashes.head())\n"
      ],
      "metadata": {
        "id": "xiyX1Fjh_KEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#print(filtered_crashes[['LATITUDE', 'LONGITUDE', 'POINT_X', 'POINT_Y']])\n",
        "filtered_crashes.loc[(filtered_crashes['POINT_X'].isna()) & (filtered_crashes['LONGITUDE'].notna()), 'POINT_X'] = filtered_crashes.loc[(filtered_crashes['POINT_X'].isna()) & (filtered_crashes['LONGITUDE'].notna()), 'LONGITUDE']\n",
        "filtered_crashes.loc[(filtered_crashes['POINT_Y'].isna()) & (filtered_crashes['LATITUDE'].notna()), 'POINT_Y'] = filtered_crashes.loc[(filtered_crashes['POINT_Y'].isna()) & (filtered_crashes['LATITUDE'].notna()), 'LATITUDE']\n",
        "\n",
        "nan_pointx_or_pointy = filtered_crashes[(filtered_crashes['POINT_X'].isna()) | (filtered_crashes['POINT_Y'].isna())]\n",
        "# all rows have both NaN so remove extra columns and rename\n",
        "#print(nan_pointx_or_pointy)\n",
        "# Remove LATITUDE and LONGITUDE columns\n",
        "filtered_crashes = filtered_crashes.drop(['LATITUDE', 'LONGITUDE'], axis=1)\n",
        "# Rename POINT_X to LATITUDE and POINT_Y to LONGITUDE\n",
        "filtered_crashes = filtered_crashes.rename(columns={'POINT_Y': 'LATITUDE', 'POINT_X': 'LONGITUDE'})\n",
        "\n",
        "\n",
        "# Individually adjusted rows missing coordinates\n",
        "################################################################################\n",
        "# Drop row 12 cross streets make no sense\n",
        "filtered_crashes.drop(index=12, inplace=True)\n",
        "# Adjust row 64 according to google maps\n",
        "filtered_crashes.loc[64, 'LATITUDE'] = 37.738925\n",
        "filtered_crashes.loc[64, 'LONGITUDE'] = -122.480794\n",
        "# Adjust row 73 according to google maps\n",
        "filtered_crashes.loc[73, 'LATITUDE'] = 37.73543018151562\n",
        "filtered_crashes.loc[73, 'LONGITUDE'] = -122.50539991980963\n",
        "# Adjust row 116 according to google maps\n",
        "filtered_crashes.loc[116, 'LATITUDE'] = 37.78328187388983\n",
        "filtered_crashes.loc[116, 'LONGITUDE'] = -122.40256946119997\n",
        "# Adjust row 168 according to google maps\n",
        "filtered_crashes.loc[168, 'LATITUDE'] = 37.7686225665498\n",
        "filtered_crashes.loc[168, 'LONGITUDE'] = -122.50026806730958\n",
        "# Adjust row 177 according to google maps- Assumption that Hobart st\n",
        "# was actually Howard as this is the closest name of a cross street\n",
        "filtered_crashes.loc[177, 'LATITUDE'] = 37.79244097342779\n",
        "filtered_crashes.loc[177, 'LONGITUDE'] = -122.39124525261985\n",
        "# Adjust row 214 according to google maps\n",
        "filtered_crashes.loc[214, 'LATITUDE'] = 37.74519409803586\n",
        "filtered_crashes.loc[214, 'LONGITUDE'] = -122.45132946120158\n",
        "# Adjust row 232 according to google maps\n",
        "filtered_crashes.loc[232, 'LATITUDE'] = 37.76830095049659\n",
        "filtered_crashes.loc[232, 'LONGITUDE'] = -122.50051460352887\n",
        "# Adjust row 320 according to google maps\n",
        "filtered_crashes.loc[320, 'LATITUDE'] = 37.73243837321172\n",
        "filtered_crashes.loc[320, 'LONGITUDE'] = -122.37537330329208\n"
      ],
      "metadata": {
        "id": "3FhG_OeitcY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Adding Census block for each datapoint\n",
        "filtered_crashes['CENSUS_TRACT'] = np.nan\n",
        "filtered_crashes['CENSUS_TRACT'] = filtered_crashes['CENSUS_TRACT'].astype(float)\n"
      ],
      "metadata": {
        "id": "GSPB80CG_EW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the data type of the 'LATITUDE' column\n",
        "latitude_dtype = filtered_crashes['LATITUDE'].dtype\n",
        "\n",
        "# Check the data type of the 'LONGITUDE' column\n",
        "longitude_dtype = filtered_crashes['LONGITUDE'].dtype\n",
        "\n",
        "print(\"Latitude Data Type:\", latitude_dtype)\n",
        "print(\"Longitude Data Type:\", longitude_dtype)"
      ],
      "metadata": {
        "id": "RYE4Utzm_x1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "181c4bbd-3d49-4fbe-fd17-6c25c68b1717",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latitude Data Type: float64\n",
            "Longitude Data Type: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade requests"
      ],
      "metadata": {
        "id": "j9M7i9ux_YAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "\n",
        "def get_census_tract(lat, lon):\n",
        "\n",
        "    \"\"\"\n",
        "    Retrieves the Census Tract (GEOID) for given latitude and longitude coordinates using the Census geocoder API.\n",
        "    Prints the full API response for debugging.\n",
        "    \"\"\"\n",
        "\n",
        "    api_url = f\"https://geocoding.geo.census.gov/geocoder/geographies/coordinates?x={lon}&y={lat}&benchmark=Public_AR_Current&vintage=Current_Current&format=json\"\n",
        "    response = requests.get(api_url)\n",
        "\n",
        "  #  print(f\"API Response for ({lat}, {lon}):\")  # Print for debugging\n",
        "  #  print(response.json())\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "\n",
        "        # Extract the GEOID from Census Tracts, if available\n",
        "        if result.get('result', {}).get('geographies', {}).get('Census Tracts'):\n",
        "            return result['result']['geographies']['Census Tracts'][0]['GEOID']\n",
        "        else:\n",
        "            print(f\"No Census Tracts data found for: {lat}, {lon}\")\n",
        "            return None  # Return None for missing data\n",
        "\n",
        "    else:\n",
        "        print(f\"Request failed for: {lat}, {lon} with status code: {response.status_code}\")\n",
        "        return None  # Return None for failed requests\n"
      ],
      "metadata": {
        "id": "YdJRiESoAMFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the DataFrame and assign Census Tracts\n",
        "for index, row in filtered_crashes.iterrows():\n",
        "    lat = row['LATITUDE']\n",
        "    lon = row['LONGITUDE']\n",
        "    census_tract = get_census_tract(lat, lon)\n",
        "    filtered_crashes.loc[index, 'CENSUS_TRACT'] = census_tract\n",
        "\n",
        "print(filtered_crashes.head())"
      ],
      "metadata": {
        "id": "XugcSEglDXbp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04f1668e-38db-4b4f-8b85-a9f465397832",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-dd70501cca55>:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '06075060100' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  filtered_crashes.loc[index, 'CENSUS_TRACT'] = census_tract\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   COLLISION_TIME                      PRIMARY_RD  \\\n",
            "0            1720  US-101 N/B (GGB EAST SIDEWALK)   \n",
            "1            1646                      US-101 S/B   \n",
            "2             851          MISSION ST. AT 6TH ST.   \n",
            "3            1449                     BAYSHORE BL   \n",
            "4             800                       SUNSET BL   \n",
            "\n",
            "                     SECONDARY_RD  DAY_OF_WEEK LOCATION_TYPE  \\\n",
            "0  GOLDEN GATE BRIDGE SOUTH TOWER            2           NaN   \n",
            "1               ALEXANDER AVE U/C            4           NaN   \n",
            "2                         7TH ST.            4           NaN   \n",
            "3                    SUNNYDALE AV            6           NaN   \n",
            "4                      VICENTE ST            1           NaN   \n",
            "\n",
            "   COLLISION_SEVERITY  NUMBER_KILLED  NUMBER_INJURED  PARTY_COUNT   LONGITUDE  \\\n",
            "0                   2              0               1            1 -122.477943   \n",
            "1                   2              0               1            1 -122.479530   \n",
            "2                   3              0               1            2 -122.410057   \n",
            "3                   3              0               1            2 -122.405426   \n",
            "4                   3              0               1            2 -122.494270   \n",
            "\n",
            "    LATITUDE CENSUS_TRACT  \n",
            "0  37.813953  06075060100  \n",
            "1  37.825527  06041131100  \n",
            "2  37.779888  06075017602  \n",
            "3  37.708431  06075026403  \n",
            "4  37.738503  06075035300  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_crashes.loc[0, 'CENSUS_TRACT'])"
      ],
      "metadata": {
        "id": "bQuGablmzRaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc2b06c2-e36a-4b2f-94ab-89e56434c169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06075060100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_crashes.to_csv('Crashes_cleaned.csv', index=False)\n",
        "files.download('Crashes_cleaned.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYHSxSp9D5I2",
        "outputId": "2ae3afd0-52de-4fe8-ff34-a5f9e8fb1f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_eec96fe6-3c86-457a-884d-9adaed27ffc2\", \"Crashes_cleaned.csv\", 30868)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Bike Features Loading/Cleaning\n"
      ],
      "metadata": {
        "id": "KxNPfQCWIO9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "bikeways = pd.read_csv('/content/SFMTA_Bikeway_2025.csv')\n",
        "# Get a list of all column names\n",
        "#all_columns = bikeways.columns.tolist()\n",
        "#print(all_columns)\n",
        "\n",
        "# Get the value of 'shape' column in the first row\n",
        "shape_value = bikeways.iloc[0]['shape']\n",
        "\n",
        "# Print the value\n",
        "print(shape_value)"
      ],
      "metadata": {
        "id": "XPPAE5htIdtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a356ee8-655c-432f-8578-4a87cdb1bbc7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POINT (-122.404748493 37.774281041)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define a function to extract coordinates\n",
        "def extract_coordinates(shape_string):\n",
        "    match = re.search(r\"POINT \\((-?\\d+\\.\\d+) (-?\\d+\\.\\d+)\\)\", shape_string)\n",
        "    if match:\n",
        "        longitude = float(match.group(1))\n",
        "        latitude = float(match.group(2))\n",
        "        return longitude, latitude\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "# Apply the function to create new columns\n",
        "bikeways[['LONGITUDE', 'LATITUDE']] = bikeways['shape'].apply(lambda x: pd.Series(extract_coordinates(x)))\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(bikeways.head())"
      ],
      "metadata": {
        "id": "FWjrDEzpOS-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9972bd3-4dbd-48c8-a87d-68515bca4a39",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   OBJECTID         CNN CORNER          STREET1         STREET2  \\\n",
            "0      2246  23875000.0      E           7TH ST       BRYANT ST   \n",
            "1      4188  24570000.0     SE  THE EMBARCADERO        BROADWAY   \n",
            "2        29  25474000.0    NaN  THE EMBARCADERO  NORTH POINT ST   \n",
            "3      5475  34141000.0     NE       MACALLA RD  YERBA BUENA RD   \n",
            "4      5133  20725000.0     NW        EVANS AVE     NAPOLEON ST   \n",
            "\n",
            "               DESCRIPT  COUNT  INSTALL_MO  INSTALL_YR  UPDATE_MO  UPDATE_YR  \\\n",
            "0           BIKE SIGNAL    2.0         4.0      2020.0        NaN        NaN   \n",
            "1        TWO-STAGE LEFT    1.0         3.0      2022.0        NaN        NaN   \n",
            "2  INTERSECTION SHARROW    2.0         6.0      2017.0        NaN        NaN   \n",
            "3              BIKE BOX    1.0         1.0      2023.0        NaN        NaN   \n",
            "4           MIXING ZONE    1.0        10.0      2022.0        NaN        NaN   \n",
            "\n",
            "                                 shape  SF Find Neighborhoods 2  \\\n",
            "0  POINT (-122.404748493 37.774281041)                     32.0   \n",
            "1  POINT (-122.397669949 37.799234483)                     77.0   \n",
            "2  POINT (-122.407301071 37.807380069)                     99.0   \n",
            "3  POINT (-122.366739204 37.811148501)                     35.0   \n",
            "4  POINT (-122.396008613 37.747262348)                     85.0   \n",
            "\n",
            "   Current Police Districts 2  Current Supervisor Districts 2  \\\n",
            "0                           1                              10   \n",
            "1                           6                               3   \n",
            "2                           6                               3   \n",
            "3                           1                              10   \n",
            "4                           2                               9   \n",
            "\n",
            "   Analysis Neighborhoods 2  Neighborhoods   LONGITUDE   LATITUDE  \n",
            "0                        34           32.0 -122.404748  37.774281  \n",
            "1                         8           77.0 -122.397670  37.799234  \n",
            "2                        23           99.0 -122.407301  37.807380  \n",
            "3                        37           35.0 -122.366739  37.811149  \n",
            "4                         1           85.0 -122.396009  37.747262  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column for Census Tract, initializing with NaN\n",
        "bikeways['CENSUS_TRACT'] = np.nan\n",
        "\n",
        "# Iterate through the DataFrame and assign Census Tracts\n",
        "for index, row in bikeways.iterrows():\n",
        "    lat = row['LATITUDE']\n",
        "    lon = row['LONGITUDE']\n",
        "    census_tract = get_census_tract(lat, lon)\n",
        "    bikeways.loc[index, 'CENSUS_TRACT'] = census_tract\n",
        "\n",
        "print(bikeways.head())"
      ],
      "metadata": {
        "id": "9NNSsxOeOiYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bikeways.to_csv('Bikeways_cleaned.csv', index=False)\n",
        "files.download('Bikeways_cleaned.csv')"
      ],
      "metadata": {
        "id": "nQY2_6jhTQfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ACS 5-year 2023 Median Income Loading/Cleaning\n"
      ],
      "metadata": {
        "id": "PRaS-oYmvUHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "Income = pd.read_csv('/content/ACSST5Y2023.S0701.income.csv')\n",
        "# Get a list of all column names\n",
        "print(Income.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twMpTJrTvT4r",
        "outputId": "ea021eaa-333a-4acc-c85f-dff589ab00b5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 GEO_ID                                               NAME  \\\n",
            "0             Geography                               Geographic Area Name   \n",
            "1  1400000US06075010101  Census Tract 101.01; San Francisco County; Cal...   \n",
            "2  1400000US06075010102  Census Tract 101.02; San Francisco County; Cal...   \n",
            "3  1400000US06075010201  Census Tract 102.01; San Francisco County; Cal...   \n",
            "4  1400000US06075010202  Census Tract 102.02; San Francisco County; Cal...   \n",
            "\n",
            "                                S0701_C01_001E  \\\n",
            "0  Estimate!!Total!!Population 1 year and over   \n",
            "1                                         2004   \n",
            "2                                         1781   \n",
            "3                                         2608   \n",
            "4                                         1749   \n",
            "\n",
            "                                      S0701_C01_001M  \\\n",
            "0  Margin of Error!!Total!!Population 1 year and ...   \n",
            "1                                                297   \n",
            "2                                                340   \n",
            "3                                                479   \n",
            "4                                                319   \n",
            "\n",
            "                                      S0701_C01_002E  \\\n",
            "0  Estimate!!Total!!Population 1 year and over!!A...   \n",
            "1                                                 62   \n",
            "2                                                 31   \n",
            "3                                                 56   \n",
            "4                                                 48   \n",
            "\n",
            "                                      S0701_C01_002M  \\\n",
            "0  Margin of Error!!Total!!Population 1 year and ...   \n",
            "1                                                 64   \n",
            "2                                                 29   \n",
            "3                                                 54   \n",
            "4                                                 57   \n",
            "\n",
            "                                      S0701_C01_003E  \\\n",
            "0  Estimate!!Total!!Population 1 year and over!!A...   \n",
            "1                                                 21   \n",
            "2                                                222   \n",
            "3                                                173   \n",
            "4                                                 42   \n",
            "\n",
            "                                      S0701_C01_003M  \\\n",
            "0  Margin of Error!!Total!!Population 1 year and ...   \n",
            "1                                                 27   \n",
            "2                                                127   \n",
            "3                                                111   \n",
            "4                                                 42   \n",
            "\n",
            "                                      S0701_C01_004E  \\\n",
            "0  Estimate!!Total!!Population 1 year and over!!A...   \n",
            "1                                                179   \n",
            "2                                                109   \n",
            "3                                                149   \n",
            "4                                                 86   \n",
            "\n",
            "                                      S0701_C01_004M  ...  \\\n",
            "0  Margin of Error!!Total!!Population 1 year and ...  ...   \n",
            "1                                                155  ...   \n",
            "2                                                 57  ...   \n",
            "3                                                116  ...   \n",
            "4                                                115  ...   \n",
            "\n",
            "                                      S0701_C05_052M  \\\n",
            "0  Margin of Error!!Moved; from abroad!!POVERTY S...   \n",
            "1                                                5.5   \n",
            "2                                                3.0   \n",
            "3                                                1.2   \n",
            "4                                                1.5   \n",
            "\n",
            "                                      S0701_C05_053E  \\\n",
            "0  Estimate!!Moved; from abroad!!HOUSING TENURE!!...   \n",
            "1                                                3.2   \n",
            "2                                                0.7   \n",
            "3                                                0.8   \n",
            "4                                                0.7   \n",
            "\n",
            "                                      S0701_C05_053M  \\\n",
            "0  Margin of Error!!Moved; from abroad!!HOUSING T...   \n",
            "1                                                4.0   \n",
            "2                                                1.0   \n",
            "3                                                1.1   \n",
            "4                                                1.4   \n",
            "\n",
            "                                      S0701_C05_054E  \\\n",
            "0  Estimate!!Moved; from abroad!!HOUSING TENURE!!...   \n",
            "1                                                0.0   \n",
            "2                                                0.0   \n",
            "3                                                0.0   \n",
            "4                                                0.0   \n",
            "\n",
            "                                      S0701_C05_054M  \\\n",
            "0  Margin of Error!!Moved; from abroad!!HOUSING T...   \n",
            "1                                               15.2   \n",
            "2                                                7.7   \n",
            "3                                                3.5   \n",
            "4                                                8.0   \n",
            "\n",
            "                                      S0701_C05_055E  \\\n",
            "0  Estimate!!Moved; from abroad!!HOUSING TENURE!!...   \n",
            "1                                                3.7   \n",
            "2                                                1.0   \n",
            "3                                                1.6   \n",
            "4                                                1.1   \n",
            "\n",
            "                                      S0701_C05_055M  \\\n",
            "0  Margin of Error!!Moved; from abroad!!HOUSING T...   \n",
            "1                                                4.5   \n",
            "2                                                1.5   \n",
            "3                                                2.0   \n",
            "4                                                2.0   \n",
            "\n",
            "                                      S0701_C05_056E  \\\n",
            "0  Estimate!!Moved; from abroad!!PERCENT ALLOCATE...   \n",
            "1                                                (X)   \n",
            "2                                                (X)   \n",
            "3                                                (X)   \n",
            "4                                                (X)   \n",
            "\n",
            "                                      S0701_C05_056M Unnamed: 562  \n",
            "0  Margin of Error!!Moved; from abroad!!PERCENT A...          NaN  \n",
            "1                                                (X)          NaN  \n",
            "2                                                (X)          NaN  \n",
            "3                                                (X)          NaN  \n",
            "4                                                (X)          NaN  \n",
            "\n",
            "[5 rows x 563 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the first row of the DataFrame\n",
        "first_row = Income.iloc[0]\n",
        "\n",
        "# Use the Income DataFrame's columns attribute directly\n",
        "median_columns = [col for col in Income.columns if \"Estimate!!Total!!INDIVIDUAL INCOME IN THE PAST\" in str(Income[col].iloc[0]) and \"Median income (dollars)\" in str(Income[col].iloc[0])]\n",
        "\n",
        "# Print the list of columns\n",
        "print(median_columns)\n",
        "\n",
        "# Select the desired columns and the first 2 rows\n",
        "subset_df = Income[median_columns]\n",
        "print(subset_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8LbxaG7HuE5",
        "outputId": "a0ae533c-d193-44ea-d3e9-2bbefe5dab0c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['S0701_C01_048E']\n",
            "                                        S0701_C01_048E\n",
            "0    Estimate!!Total!!INDIVIDUAL INCOME IN THE PAST...\n",
            "1                                                73156\n",
            "2                                                31184\n",
            "3                                               101007\n",
            "4                                                94715\n",
            "..                                                 ...\n",
            "240                                              13078\n",
            "241                                              68456\n",
            "242                                              53900\n",
            "243                                                  -\n",
            "244                                                  -\n",
            "\n",
            "[245 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the Income DataFrame's columns attribute directly\n",
        "median_columns = [col for col in Income.columns if \"Estimate!!Total!!INDIVIDUAL INCOME IN THE PAST\" in str(Income[col].iloc[0]) and \"Median income (dollars)\" in str(Income[col].iloc[0])]\n",
        "\n",
        "# Get the name of the first column\n",
        "first_column_name = Income.columns[0]\n",
        "\n",
        "# Create a new DataFrame with the first column and columns from median_columns (all rows)\n",
        "new_df = Income[[first_column_name] + median_columns]\n",
        "\n",
        "\n",
        "# Remove the first row\n",
        "new_df = new_df.iloc[1:]  # Select rows from index 1 onwards\n",
        "\n",
        "# Rename the first and second columns\n",
        "new_df = new_df.rename(columns={new_df.columns[0]: \"Census Tract\", new_df.columns[1]: \"Median Income\"})\n",
        "\n",
        "# Print the new DataFrame\n",
        "print(new_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY2gVjiZMEbh",
        "outputId": "1fa3a989-d926-4357-a27a-9c7d939a7f0d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Census Tract Median Income\n",
            "1    1400000US06075010101         73156\n",
            "2    1400000US06075010102         31184\n",
            "3    1400000US06075010201        101007\n",
            "4    1400000US06075010202         94715\n",
            "5    1400000US06075010300         99279\n",
            "..                    ...           ...\n",
            "240  1400000US06075980501         13078\n",
            "241  1400000US06075980600         68456\n",
            "242  1400000US06075980900         53900\n",
            "243  1400000US06075990100             -\n",
            "244  1400000US06075990200             -\n",
            "\n",
            "[244 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def format_census_tract(tract_id):\n",
        "  try:\n",
        "    # Extract the part after 'US'\n",
        "    extracted_id = tract_id.split('US')[1]\n",
        "\n",
        "    # Pad with zeros if necessary\n",
        "    formatted_id = extracted_id.zfill(11)  # Pad to 11 digits with leading zeros\n",
        "\n",
        "    return formatted_id\n",
        "  except IndexError:\n",
        "    # Handle cases where 'US' is not found\n",
        "    return tract_id\n",
        "\n",
        "# Apply the function to the 'Census Tract' column\n",
        "new_df['Census Tract'] = new_df['Census Tract'].apply(format_census_tract)\n",
        "\n",
        "nan_rows = new_df[new_df.isna().any(axis=1)]\n",
        "print(nan_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCzIa-CMOwtS",
        "outputId": "9f00a178-376e-40c8-dfe7-0c019ad3d349",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Census Tract, Median Income]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.to_csv('Income_cleaned.csv', index=False)\n",
        "files.download('Income_cleaned.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Fq7v8vMEPa2P",
        "outputId": "e9f46843-05c5-48d6-ffb3-0e4d1c17aabe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c92e3f3a-7af9-4e9a-be51-33cecb9cf39a\", \"Income_cleaned.csv\", 4461)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}